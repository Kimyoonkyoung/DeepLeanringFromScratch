# LearningTechnic

***

## Optimizer

### SGD
손실함수의 기울기를 learning rate을 곱한 후 기존 가중치에서 빼주는 방법
* 단점
    * 비등방성함수 (방향에 따라서 기울기가 달라지는 함수) 에서는 탐색 경로가 비효율적임
    * 비등방성함수 같은 경우에는, 기울기가 최솟값과 다른 방향을 가리키기 때문
    
### momentum
현재 속도(방향성을 가짐) 및 운동에너지를 효과적으로 감소시키도록 하는 방법

### AdaGrad
각각의 매개변수에 맞춤형 learning rate decay 를 적용시키는 방법
* 원리
    * 기울기 값을 제곱해서 더해줌 -> 갱신할 때, 앞에 더해준값의 루트를 씌워서 나눠줌
    * 즉, 매개변소 원소 중에서 많이 움직인 (크게 갱신된) 원소는 학습률이 낮아짐
    * 나눠줄 때, 0으로 나누는 것을 방지하기 위하여 매우 작은값을 더해
* 단점
    * 과거의 기울기를 계속 제곱하고 더함으로써, 갱신 강도가 점점점 약해짐
    * 실제로 계속 학습하면, learning rate 이 0이 되는 경우가 있음
    
### RMSProp
AdaGrad 의 발전 방법
* 원리
    * 과거의 모든 기울기를 균일하게 더해가는 것이 아니라, 먼 과거의 기울기는 서서히 잊고 새로운 것을 크게 반영하는 방법
    * 이를 지수이동평균(EMA, Exponential moving Average)라고 하여, 과거기울기를 기하급수적으로 감소시킴
    
### Adam
AdaGrad 와 Adam 의 혼합 방법 (2015년도에 제안된 방법)
* 원리
    * 하이퍼파라미터의 편향 보정이 진행됨
    * 세개의 하이퍼파라미터를 설정함
        * 현재까지의 학습률
        * 일차 모맨텀용 계수 (0.9 추천)
        * 이차 모맨텀용 계수 (0.999 추천)
        
### optimizer 선택 방법
* 현재까지는 SGD, Adam 을 많이 사용하고 있음
* 각 데이터마다 특성을 확인해서 해야함

## 가중치의 초기값

### 모든 가중치를 0으로 하게 된다면?
* 모든 가중치를 0으로 하거나, 아예 같은 값으로 설정한다면, 학습이 이루어지지 않음

## 은닉층의 활성화값 분포

### sigmoid 에서의 초기값
* 초기값을 랜덤으로 뽑을 때 표준편차를 1로 설정한다면,
    * 기울기가 0에 가까운것은 0으로, 1에 가까운것은 1로 가다가 결국 기울기가 사라짐
    * 기울기가 소실되는 현상은 (gradient vanishing) 이라고 함
* 초기값을 랜덤으로 뽑을 때 표준편차를 0.1로 설정한다면,
    * 기울기 소실 문제는 일어나지 않지만, 가운데로 점점 모이게 됨
    * 가운데로 모이게되면 (활성화값이 치우치면) 표현력을 제한한다는 관점에서 문제가 됨
* Xavier 초기값
    * 일반적인 딥러닝 프레임웍들이 표준으로 사용하고 있는 방법
    * input 노드의 갯수를 n 이라고 할때, 표준편차를 1/루트n 으로 설정
    * sigmoid 가 원점대칭이 아니기 떄문에, 학습할수록 기울기가 일그러지기는 함
    * 이 방법은 sigmoid 중심부분을 선형이라고 볼 수 있기 때문에 적용하면 효율적임
    
### ReLU 에서의 초기값
* He 초기값
    * 루트(2/n) 으로 설정
    * 음의 영역을 0으로 바꾸기 때문에, Xavier 보다 더 넓게 분포시키기 위해서 2배의 계수를 적용
    
## 배치정규화 (batch normalization)
각 층이 활성화를 적당히 퍼트리도록 '강제' 하는 방법 (2015년에 제안)

### 알고리즘
* 장점
    * 학습을 빨리 진행할 수 있음
    * 초깃값에 크게 의존하지 않음
    * 오버피팅 억제
    
* 방법
    * 정규화는 미니배치 단위로 수행
    * m개의 입력 데이터의 집합에 대해 평균과 분산을 구하고
    * 평균이 0, 분산이 1 이 되게 정규화함
    * 0으로 나누는 것을 방지하기 위해서 적절히 작은값을 넣어줌
    * 활성화함수 앞이나 뒤에 삽입
    * 또한, 정규화 계층마다 정규화된 데이터에 확대와 이동을 수행함
    * 확대는 1로, 이동은 0부터 시작하고 학습하면서 적합하게 조정해감
    
## 오버피팅
### 가중치 감소 (weight decay)
학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하여 오버피팅을 억제하는 방법
* 방법
    * 모든 가중치에 (1/2)*람다*(W^2) 를 추가로 '더해줌'
    * 1/2 : 미분 할 때, 편하게 하기위한 상수
    * 람다 : 정규화의 세기를 조절하는 하이퍼파라미터
* 단점
    * 신경망이 복잡해지면, 한계가 발생함
    
### 드롭아웃 (drop out)
뉴런을 임의로 삭제하면서 학습하는 방법
* 방법
    * 학습할 때 hidden layer의 뉴런을 무작위로 삭제
    * test 때는 모든 뉴런에 신호를 전달하지만, 각 뉴런의 출력에 학습 때 삭제한 비율을 곱해줌
    * 순전파 때, 뉴런 갯수와 같은 배열을 생성하고 랜덤값을 넣어 논 다음에, dropout_ratio 보다 큰애만 true, 아니면 false로 설정
    * 역전파 때, ReLU와 같은 방식으로 false 면 그냥 통과
    
## 앙상블 학습
개별적으로 학습시킨 여러 모델의 출력을 평균 내어 추론하는 방식
* 방법
    * 같은 혹은 비슷한 구조의 네트워크를 n개 준비하여 따로따로 학습함
    * test 때 각각의 출력을 평균냄
* 드롭아웃과 비슷한 원리
    * 드롭아웃이 학습 때 무작위로 삭제하는 것이 곧 다른 모델을 학습하는 것으로 해석할 수 있음
    * 또한 test 할 때, 삭제 비율을 곱함으로써 평균내는 것과 같은 것으로 해석할 수 있음
    
## 적절한 하이퍼파라미터 찾기

### validation data
하이퍼파라미터 성능 평가용 데이터 (일반적으로 training data 의 20% 정도)
* 데이터 분류
    * training data : 매개변수(weight, bias) 학습
    * validation data : 하이퍼파라미터(learning rate, neuron 수, batch 크기, weight decay 등)
    * test data : 리얼 성능 평가

### 하이퍼파라미터 최적화
'최적 값'이 존재하는 범위를 조금씩 줄여간다는 의미
* 순서 (에폭을 작게! - 시간이 오래걸리니까)
    1. 하이퍼파라미터 값의 범위를 설정
        * 범위는 대략적으로 지정 (0.001~1000 사이 처럼 10의 계승단위로 설정) -> 로그스케일
    2. 설정된 범위에서 하이퍼파라미터 값을 무작위로 추출
        * grid search 같은 방법보다, 무작위로 샘플링 해서 탐색하는 것이 효율적임
    3. 2단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가
    4. 2단계와 3단계를 특정 횟수 (100회 등) 반복하여, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다
    5. 잘될 것 같은 값의 범위를 관찰하고 범위를 좁혀나감
    6. 좁힌 범위로 똑같은 작업을 반복
* 베이즈 최적화(bayesian optimization) 방법이 있음
